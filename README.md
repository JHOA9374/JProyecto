#  Predicci贸n de Distancia de Transmisi贸n en Motes: Comparativa entre Modelos Superficiales y Profundos

##  Descripci贸n

Este proyecto implementa modelos de **Machine Learning supervisado** para predecir la **distancia de transmisi贸n** de motes (nodos sensores inal谩mbricos), utilizando m茅tricas de rendimiento como tasa de 茅xito, n煤mero de p茅rdidas, varianza y racha m谩s larga de p茅rdidas consecutivas. Se comparan dos enfoques:

1. **Modelo superficial**: Random Forest Classifier.
2. **Modelo profundo**: Red neuronal utilizando TensorFlow/Keras.

El objetivo es evaluar cu谩l modelo se adapta mejor a los datos de m茅tricas de transmisi贸n y estimar la distancia con mayor precisi贸n y robustez.

##  Dataset
EL datset original se encuentra alojado en:

https://data.mendeley.com/datasets/r6skswb8s4/2

El dataset prepara para entrenamiento contiene las siguientes caracter铆sticas:

- `success_rate`: Proporci贸n de paquetes recibidos exitosamente.
- `loss_count`: N煤mero de paquetes perdidos.
- `varianza`: Desviaci贸n est谩ndar de las m茅tricas de transmisi贸n.
- `longest_loss_streak`: Racha m谩s larga de p茅rdidas consecutivas.
- `distancia`: Distancia de transmisi贸n (en metros), variable objetivo.

## 锔 Metodolog铆a

1. **Preprocesamiento de datos**: Selecci贸n de caracter铆sticas relevantes y preparaci贸n del conjunto de datos.
2. **Divisi贸n de datos**: Separaci贸n en conjuntos de entrenamiento (60%), prueba (20%) y validaci贸n (20%).
3. **Entrenamiento de modelos**:
   - *Modelo superficial*: Random Forest con optimizaci贸n de hiperpar谩metros usando GridSearchCV.
   - *Modelo profundo*: Red neuronal con capas densas, activaci贸n ReLU y optimizaci贸n con Adam.
4. **Evaluaci贸n**:
   - M茅tricas: Accuracy, F1-score (macro y weighted).
   - Matriz de confusi贸n.
   - Curvas de aprendizaje y p茅rdidas.

##  Resultados

Modelo Superficial (Random Forest)

M茅tricas simples (success_rate, loss_count, varianza, longest_loss_streak)

<img width="951" height="403" alt="image" src="https://github.com/user-attachments/assets/ed955958-432e-40ff-9b47-86e5201a36e9" />


- Accuracy (Validation): 0.500
- F1-score (macro): 0.500
- F1-score (weighted): 0.500
- Accuracy promedio CV: 0.767 卤 0.207

M茅tricas complejas (features derivadas o agregadas)

<img width="835" height="373" alt="image" src="https://github.com/user-attachments/assets/770e6b4c-6bda-416f-8131-06847922aed7" />


- Accuracy (Validation): 1.000
- F1-score (macro): 1.000
- F1-score (weighted): 1.000
- Accuracy promedio CV: 0.983 卤 0.033

Nota: Las m茅tricas complejas mejoran significativamente el desempe帽o del modelo superficial, mostrando la importancia de una buena selecci贸n de features.

Modelo Profundo (Red Neuronal)

M茅tricas simples
<img width="953" height="393" alt="image" src="https://github.com/user-attachments/assets/10ae100c-c5c2-4a43-acd1-47ca519815e7" />

Clase | Precision | Recall | F1-score | Support
------|-----------|--------|----------|--------
0     | 0.50      | 0.56   | 0.53     | 9
1     | 0.50      | 0.44   | 0.47     | 9

- Accuracy (Validation): 0.50
- F1-score (macro): 0.50
- F1-score (weighted): 0.50

M茅tricas complejas
<img width="986" height="424" alt="image" src="https://github.com/user-attachments/assets/840ab39a-a27e-4242-ab1e-1429bd189673" />

- Accuracy (Validation): 1.00
- F1-score (macro): 1.00
- F1-score (weighted): 1.00

Nota: Al igual que en el modelo superficial, las m茅tricas complejas aumentan dr谩sticamente el rendimiento del modelo profundo, alcanzando predicciones perfectas en los datos de validaci贸n.

## Conclusiones

- Ambos modelos dependen fuertemente de la calidad y complejidad de las features.
- Con m茅tricas simples, el desempe帽o es limitado (accuracy ~0.5).
- Con m茅tricas complejas, se alcanza accuracy perfecto (1.0).
- El modelo profundo puede escalar mejor a datasets m谩s grandes o ruidosos, aunque ambos muestran un comportamiento similar frente a la complejida



##  Instalaci贸n

Clonar el repositorio e instalar las dependencias:

```bash
git clone https://github.com/JHOA9374/JProyecto.git
cd JProyecto
pip install -r requirements.txt
