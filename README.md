# üì° Predicci√≥n de Distancia de Transmisi√≥n en Motes: Comparativa entre Modelos Superficiales y Profundos

## üìñ Descripci√≥n

Este proyecto implementa modelos de **Machine Learning supervisado** para predecir la **distancia de transmisi√≥n** de motes (nodos sensores inal√°mbricos), utilizando m√©tricas de rendimiento como tasa de √©xito, n√∫mero de p√©rdidas, varianza y racha m√°s larga de p√©rdidas consecutivas. Se comparan dos enfoques:

1. **Modelo superficial**: Random Forest Classifier.
2. **Modelo profundo**: Red neuronal utilizando TensorFlow/Keras.

El objetivo es evaluar cu√°l modelo se adapta mejor a los datos de m√©tricas de transmisi√≥n y estimar la distancia con mayor precisi√≥n y robustez.

## üìä Dataset

El dataset contiene las siguientes caracter√≠sticas:

- `success_rate`: Proporci√≥n de paquetes recibidos exitosamente.
- `loss_count`: N√∫mero de paquetes perdidos.
- `varianza`: Desviaci√≥n est√°ndar de las m√©tricas de transmisi√≥n.
- `longest_loss_streak`: Racha m√°s larga de p√©rdidas consecutivas.
- `distancia`: Distancia de transmisi√≥n (en metros), variable objetivo.

## ‚öôÔ∏è Metodolog√≠a

1. **Preprocesamiento de datos**: Selecci√≥n de caracter√≠sticas relevantes y preparaci√≥n del conjunto de datos.
2. **Divisi√≥n de datos**: Separaci√≥n en conjuntos de entrenamiento (60%), prueba (20%) y validaci√≥n (20%).
3. **Entrenamiento de modelos**:
   - *Modelo superficial*: Random Forest con optimizaci√≥n de hiperpar√°metros usando GridSearchCV.
   - *Modelo profundo*: Red neuronal con capas densas, activaci√≥n ReLU y optimizaci√≥n con Adam.
4. **Evaluaci√≥n**:
   - M√©tricas: Accuracy, F1-score (macro y weighted).
   - Matriz de confusi√≥n.
   - Curvas de aprendizaje y p√©rdidas.

## üìà Resultados

Modelo Superficial (Random Forest)

M√©tricas simples (success_rate, loss_count, varianza, longest_loss_streak)

<img width="951" height="403" alt="image" src="https://github.com/user-attachments/assets/ed955958-432e-40ff-9b47-86e5201a36e9" />


- Accuracy (Validation): 0.500
- F1-score (macro): 0.500
- F1-score (weighted): 0.500
- Accuracy promedio CV: 0.767 ¬± 0.207

M√©tricas complejas (features derivadas o agregadas)

<img width="835" height="373" alt="image" src="https://github.com/user-attachments/assets/770e6b4c-6bda-416f-8131-06847922aed7" />


- Accuracy (Validation): 1.000
- F1-score (macro): 1.000
- F1-score (weighted): 1.000
- Accuracy promedio CV: 0.983 ¬± 0.033

Nota: Las m√©tricas complejas mejoran significativamente el desempe√±o del modelo superficial, mostrando la importancia de una buena selecci√≥n de features.

Modelo Profundo (Red Neuronal)

M√©tricas simples
<img width="953" height="393" alt="image" src="https://github.com/user-attachments/assets/10ae100c-c5c2-4a43-acd1-47ca519815e7" />

Clase | Precision | Recall | F1-score | Support
------|-----------|--------|----------|--------
0     | 0.50      | 0.56   | 0.53     | 9
1     | 0.50      | 0.44   | 0.47     | 9

- Accuracy (Validation): 0.50
- F1-score (macro): 0.50
- F1-score (weighted): 0.50

M√©tricas complejas
<img width="986" height="424" alt="image" src="https://github.com/user-attachments/assets/840ab39a-a27e-4242-ab1e-1429bd189673" />

- Accuracy (Validation): 1.00
- F1-score (macro): 1.00
- F1-score (weighted): 1.00

Nota: Al igual que en el modelo superficial, las m√©tricas complejas aumentan dr√°sticamente el rendimiento del modelo profundo, alcanzando predicciones perfectas en los datos de validaci√≥n.

Conclusi√≥n Comparativa

- Ambos modelos dependen fuertemente de la calidad y complejidad de las features.
- Con m√©tricas simples, el desempe√±o es limitado (accuracy ~0.5).
- Con m√©tricas complejas, se alcanza accuracy perfecto (1.0).
- El modelo profundo puede escalar mejor a datasets m√°s grandes o ruidosos, aunque ambos muestran un comportamiento similar frente a la complejida


## üõ†Ô∏è Tecnolog√≠as utilizadas

- Python 3.x
- scikit-learn
- TensorFlow / Keras
- pandas
- numpy
- matplotlib
- seaborn

## üöÄ Instalaci√≥n

Clonar el repositorio e instalar las dependencias:

```bash
git clone https://github.com/JHOA9374/JProyecto.git
cd JProyecto
pip install -r requirements.txt
